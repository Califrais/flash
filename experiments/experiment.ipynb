{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lights model tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lights.simulation import SimuJointLongitudinalSurvival\n",
    "from lights.base.utils import heatmap, annotate_heatmap, gompertz_pdf, \\\n",
    "                              gompertz_survival, visualize_vect_learning, visualize_vect_per_group\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from lifelines.utils import concordance_index as c_index_score\n",
    "from IPython.display import Markdown, display\n",
    "from scipy.stats import beta\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load configuration\n",
    "import json\n",
    "with open('experiment.json') as f:\n",
    "    conf = json.load(f)\n",
    "print(json.dumps(conf, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_long_features = 5\n",
    "n_time_indep_features = 10\n",
    "simu = SimuJointLongitudinalSurvival(seed=123, n_long_features=n_long_features, n_samples=conf[\"n_samples\"],\n",
    "                                     n_time_indep_features = n_time_indep_features, std_error=conf[\"std_error\"],\n",
    "                                     coeff_val_asso_low_risk=conf[\"coeff_val_asso_low_risk\"],\n",
    "                                     coeff_val_asso_high_risk=conf[\"coeff_val_asso_high_risk\"],\n",
    "                                    fixed_effect_mean_low_risk=conf[\"fixed_effect_mean_low_risk\"],\n",
    "                                    fixed_effect_mean_high_risk=conf[\"fixed_effect_mean_high_risk\"],\n",
    "                                     cov_corr_long = conf[\"cov_corr_long\"], sparsity = conf[\"sparsity\"],\n",
    "                                     shape = conf[\"baseline_shape\"], scale = conf[\"baseline_scale\"])\n",
    "X, Y, T, delta, S_k = simu.simulate()\n",
    "\n",
    "printmd(\"\\nLevel of censoring: **%.1f%%**\" % (100*(1 - delta.mean())))\n",
    "printmd(\"\\nLevel of high-risk group: **%.1f%%**\" % (100*(1 - simu.G.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize parameter vectors\n",
    "We generate survival times with a risk model of the form\n",
    "$$\\begin{align*}\n",
    "\\lambda_i(t|G_i = k) &= \\lambda_0(t) \\exp \\Big\\{ x_i^\\top \\xi + \\sum_{l=1}^L \\gamma_{k,1}^l (\\beta_{k,1}^l + \\beta_{k,2}^l t + b_{i,1}^l + b_{i,2}^l t) + (\\gamma_{k,2,1}^l b_{i,1}^l + \\gamma_{k,2,2}^l b_{i,2}^l) + \\gamma_{k,3}^l (\\beta_{k,2}^l + b_{i,2}^l) \\Big\\} \\\\\n",
    "&= \\lambda_0(t) \\exp \\big\\{ \\iota_{i,k,1} + \\iota_{i,k,2} t \\big\\}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xi, betas, gammas = simu.time_indep_coeffs, simu.fixed_effect_coeffs, simu.asso_coeffs\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "fontsize = 16\n",
    "ax = fig.add_subplot(111)\n",
    "ax.stem(xi, linefmt='g-', markerfmt='go')\n",
    "ax.set_xlim([-5, len(xi) + 5])\n",
    "ax.set_title(r\"$\\xi$\", fontsize=fontsize+4)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "names, colors, labels = ['beta', 'gamma'], ['b', 'r'], ['Low-risk', 'High-risk']\n",
    "j = 1\n",
    "\n",
    "for i, vectors in enumerate([betas, gammas]):\n",
    "    for k in [0, 1]:\n",
    "        name = names[i]\n",
    "        ax = fig.add_subplot(2,2,j)\n",
    "        j += 1\n",
    "        ax.stem(vectors[k], linefmt='%s-' % colors[k], \n",
    "                markerfmt='%so' % colors[k], label=labels[k])\n",
    "        ax.set_xlim([-5, len(vectors[k]) + 5])\n",
    "        ax.set_title(r\"$\\%s_%s$\" % (name, k), fontsize=fontsize+4)\n",
    "        plt.yticks(fontsize=fontsize)\n",
    "        plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "        plt.legend(fontsize=fontsize-2)\n",
    "        visualize_vect_per_group(vectors[k], n_long_features, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize simulated times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a Gompertz distribution for the baseline, that is\n",
    "$$\\lambda_0(t) = \\kappa_1 \\kappa_2 \\exp(\\kappa_2t)$$\n",
    "with $\\kappa_1 > 0$ and $\\kappa_2 \\in R$ the scale and shape parameters respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale, shape = simu.scale, simu.shape\n",
    "print(\"kappa_1=%s, kappa_2=%s\" % (scale, shape))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "# Density function plot\n",
    "ax = fig.add_subplot(121)\n",
    "t = np.linspace(0, 100, 100)\n",
    "ax.plot(t, gompertz_pdf(t, shape, scale), '-', color='darkorange', lw=3, alpha=0.6)\n",
    "plt.xlabel(r\"$t$\", fontsize=fontsize+4)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.title(r\"$f_0(t) = \\kappa_1 \\kappa_2 \\exp (\\kappa_1 + \\kappa_2 t -\\kappa_1 e^{\\kappa_2 t})$\", \n",
    "          size=fontsize+2)\n",
    "\n",
    "# Survival function plot\n",
    "ax = fig.add_subplot(122)\n",
    "t = np.linspace(0, 100, 100)\n",
    "ax.plot(t, gompertz_survival(t, shape, scale), '-', color='darkorange', lw=3, alpha=0.6)\n",
    "plt.xlabel(r\"$t$\", fontsize=fontsize+4)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.title(r\"$S_0(t) = \\exp (-\\kappa_1 (e^{\\kappa_2 t} - 1) )$\", size=fontsize+2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "iotas = simu.iotas\n",
    "for i in [1, 2]:\n",
    "    ax = fig.add_subplot(1,2,i)\n",
    "    iota_0i, iota_1i = iotas[i]\n",
    "    all_iota = list(iota_0i) + list(iota_1i)\n",
    "    mini, maxi = min(all_iota), max(all_iota)\n",
    "    bins = np.linspace(mini, maxi, 40)\n",
    "    kwargs = dict(bins=bins, alpha=0.6, rwidth=0.9)\n",
    "    plt.hist(iota_1i, **kwargs, color='r', label='High-risk')\n",
    "    plt.hist(iota_0i, **kwargs, color='b', label='Low-risk')\n",
    "    plt.xlabel(r\"$\\iota_{i,k,%s}$\" % i, size=fontsize + 5)\n",
    "    plt.ylabel(\"Count\", size=fontsize)\n",
    "    plt.legend(fontsize=fontsize-2)\n",
    "    ax.tick_params(labelsize=fontsize-2)\n",
    "    plt.title(\"Frequency histogram of \" + r'$\\iota_{i,k,%s}$' % i, size=fontsize+2)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "G = simu.latent_class\n",
    "T_star = simu.event_times\n",
    "times, labels = [T_star, T], ['T^\\star', 'T']\n",
    "for i in [0, 1]:\n",
    "    ax = fig.add_subplot(1,3,i+1)\n",
    "    df = pd.DataFrame(data={\"time\": times[i], \"group\": G})\n",
    "    bins = np.linspace(0, times[i].max(), 40)\n",
    "    kwargs = dict(bins=bins, alpha=0.6, rwidth=0.9)\n",
    "    plt.hist(df.loc[df.group == 1, 'time'], **kwargs, color='r', label='High-risk')\n",
    "    plt.hist(df.loc[df.group==0, 'time'], **kwargs, color='b', label='Low-risk')\n",
    "    plt.legend(fontsize=fontsize-2)\n",
    "    plt.xlabel(r'$%s$' % labels[i], size=fontsize+2)\n",
    "    plt.ylabel(\"Count\", size=fontsize)\n",
    "    ax.tick_params(labelsize=fontsize-2)\n",
    "    plt.title(\"Frequency histogram of \" + r'$%s$' % labels[i], size=fontsize+2)\n",
    "\n",
    "# Kaplan Meier estimation of survival curves\n",
    "kmf = KaplanMeierFitter()\n",
    "ax = plt.subplot(133)\n",
    "kmf.fit(T[G == 1], delta[G == 1], label=\"High-risk\").plot(ax=ax, c='r')\n",
    "kmf.fit(T[G == 0], delta[G == 0], label=\"Low-risk\").plot(ax=ax, c='b')\n",
    "plt.legend(fontsize=fontsize-2)\n",
    "plt.xlabel('Time $t$', size=fontsize)\n",
    "plt.ylabel(r'$P[S > t]$', size=fontsize+2)\n",
    "plt.title(\"Estimated survival curves\", size=fontsize+2)\n",
    "ax.tick_params(labelsize=fontsize-2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize longitudinal processes for two subjects randomly chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax0 = plt.subplot(n_long_features,1,1)\n",
    "colors, labels = ['b', 'r'], ['Low-risk', 'High-risk']\n",
    "for k in [0, 1]:\n",
    "    idx = np.random.choice(Y[G == k].index)\n",
    "    Y_i = Y.loc[idx, :]\n",
    "    label, color = labels[k], colors[k]\n",
    "    for l in range(1, n_long_features + 1):\n",
    "        Y_il = Y_i[\"long_feature_%s\" % l]\n",
    "        ax = plt.subplot(n_long_features,1 ,l , sharex=ax0)\n",
    "        Y_il.plot(label=label, color=color, marker='H')\n",
    "        ax.set_title(\"Longitudinal feature %s\" % l, fontsize=fontsize+4)\n",
    "        plt.xticks(fontsize=fontsize), plt.yticks(fontsize=fontsize)\n",
    "        plt.legend(fontsize=fontsize-2)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lights.cross_val import cross_validate\n",
    "\n",
    "best_param = cross_validate (X, Y, T, delta, S_k,  n_folds=conf[\"n_folds\"], \n",
    "                             grid_size=conf[\"grid_size\"], zeta_gamma_max = conf[\"zeta_gamma_max\"],\n",
    "                            max_iter=conf[\"max_iter\"], max_iter_lbfgs=conf[\"max_iter_lbfgs\"], \n",
    "                             max_iter_proxg=conf[\"max_iter_proxg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets \n",
    "test_size = .3  # proportion of data used for testing\n",
    "rs = ShuffleSplit(n_splits=1, test_size=test_size, random_state=0)\n",
    "\n",
    "for train_index, test_index in rs.split(X):\n",
    "    X_test = X[test_index]\n",
    "    Y_test = Y.iloc[test_index, :]\n",
    "    T_test = T[test_index]\n",
    "    delta_test = delta[test_index]\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    Y_train = Y.iloc[train_index, :]\n",
    "    T_train = T[train_index]\n",
    "    delta_train = delta[train_index]\n",
    "    \n",
    "print(\"%d%% for training, %d%% for testing.\" \n",
    "      % ((1 - test_size) * 100, test_size * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lights.inference import prox_QNMCEM\n",
    "\n",
    "## Choose parameters ##\n",
    "tol = 1e-6            # tolerance for the convergence stopping criterion \n",
    "eta = 0.3             # parameter controlling the trade-off between l1 \n",
    "                      # and l2 regularization in the elasticNet\n",
    "gamma_chosen = '1se'  # way to select l_elasticNet_chosen: '1se' or 'min'\n",
    "warm_start = True     # at each L-BGFS-B iteration, reset beta to 0 or take \n",
    "                      # the previous value \n",
    "grid_size = 30        # grid size for the cross validation procedure\n",
    "metric = 'C-index'    # cross-validation metric: 'log_lik' or 'C-index'\n",
    "\n",
    "# Training with best cross-validation params\n",
    "l_pen_EN, l_pen_SGL = best_param\n",
    "learner = prox_QNMCEM(fixed_effect_time_order=1, max_iter=conf[\"max_iter\"],\n",
    "                      max_iter_lbfgs=conf[\"max_iter_lbfgs\"], \n",
    "                      max_iter_proxg=conf[\"max_iter_proxg\"], compute_obj=True, print_every=1,\n",
    "                      l_pen_SGL=l_pen_SGL, eta_sp_gp_l1=conf[\"eta_sp_gp_l1\"], \n",
    "                      asso_functions=[\"lp\", \"re\"], l_pen_EN=l_pen_EN,\n",
    "                      initialize=True)\n",
    "if learner.simu:\n",
    "    learner.fit(X_train, Y_train, T_train, delta_train, S_k, conf[\"cov_corr_rdn_long\"])\n",
    "else:\n",
    "    learner.fit(X_train, Y_train, T_train, delta_train)\n",
    "    \n",
    "\n",
    "# Visualize learning\n",
    "visualize_vect_learning(learner, \"obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize beta_0\n",
    "true_beta_0 = simu.fixed_effect_coeffs[0].reshape(-1, 1)\n",
    "to = len(true_beta_0)+1\n",
    "leg1 = [r\"$\\hat \\beta^0_%s$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\beta^0_%s$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"beta_0\", r\"$\\beta_0$\", true_beta_0, leg1, leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize beta_1\n",
    "true_beta_1 = simu.fixed_effect_coeffs[1].reshape(-1, 1)\n",
    "to = len(true_beta_1)+1\n",
    "leg1 = [r\"$\\hat \\beta^1_%s$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\beta^1_%s$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"beta_1\", r\"$\\beta_1$\", true_beta_1, leg1, leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta_0_true = true_beta_0\n",
    "beta_0_est = learner.theta[\"beta_0\"]\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fontsize = 16\n",
    "ax = fig.add_subplot(121)\n",
    "ax.stem(np.arange(len(beta_0_true)).tolist(), beta_0_true, linefmt='g-', markerfmt='go', label= r\"$\\beta_0$\")\n",
    "ax.stem((np.arange(len(beta_0_est)) + .5).tolist(), beta_0_est, linefmt='r-', markerfmt='rx', label= r\"$\\hat \\beta_0$\")\n",
    "ax.set_xlim([-5, len(beta_0_true) + 5])\n",
    "ax.set_title(r\"$\\beta_0$ and its estimation\", fontsize=fontsize+4)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "visualize_vect_per_group(beta_0_true, n_long_features, ax)\n",
    "\n",
    "beta_1_true = true_beta_1\n",
    "beta_1_est = learner.theta[\"beta_1\"]\n",
    "fontsize = 16\n",
    "ax = fig.add_subplot(122)\n",
    "ax.stem(np.arange(len(beta_1_true)).tolist(), beta_1_true, linefmt='g-', markerfmt='go', label= r\"$\\beta_1$\")\n",
    "ax.stem((np.arange(len(beta_1_est)) + .5).tolist(), beta_1_est, linefmt='r-', markerfmt='rx', label= r\"$\\hat \\beta_1$\")\n",
    "ax.set_xlim([-5, len(beta_1_true) + 5])\n",
    "ax.set_title(r\"$\\beta_1$ and its estimation\", fontsize=fontsize+4)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "visualize_vect_per_group(beta_1_true, n_long_features, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize phi\n",
    "true_phi = np.array([simu.std_error ** 2] * simu.n_long_features).reshape(-1, 1)\n",
    "to = len(true_phi)+1\n",
    "leg1 = [r\"$\\hat \\phi_%s$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\phi_%s$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"phi\", symbol = r\"$\\phi$\", true_coeffs = true_phi, legend_est = leg1, legend_true = leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize xi\n",
    "true_xi = simu.time_indep_coeffs.reshape(-1, 1)\n",
    "to = len(true_xi)+1\n",
    "leg1 = [r\"$\\hat \\xi_%s$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\xi_%s$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"xi\", r\"$\\xi$\", true_xi, leg1, leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_true = true_xi\n",
    "xi_est = learner.theta[\"xi\"]\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "fontsize = 16\n",
    "ax = fig.add_subplot(111)\n",
    "ax.stem(np.arange(len(xi_true)).tolist(), true_xi, linefmt='g-', markerfmt='go', label= r\"$\\xi$\")\n",
    "ax.stem((np.arange(len(xi_est)) + .5).tolist(), xi_est, linefmt='r-', markerfmt='rx', label= r\"$\\hat \\xi$\")\n",
    "ax.set_xlim([-5, len(true_xi) + 5])\n",
    "ax.set_title(r\"$\\xi$ and its estimation\", fontsize=fontsize+4)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "$\\gamma'$ is optimized by Copt solver without adding the intercept (ones column vector).\n",
    "\n",
    "$\\gamma$ is denormalized by the its feature standard deviation.\n",
    "$$\\gamma = \\frac{\\gamma'}{std(\\Psi)} $$\n",
    "with $\\Psi$ denotes the association features vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gamma_0\n",
    "true_gamma_0 = simu.asso_coeffs[0].reshape(-1, 1)\n",
    "to = len(true_gamma_0)+1\n",
    "leg1 = [r\"$\\hat \\gamma^0_{%s}$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\gamma^0_{%s}$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"gamma_0\", r\"$\\gamma_0$\", true_gamma_0, leg1, leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gamma_1\n",
    "true_gamma_1 = simu.asso_coeffs[1].reshape(-1, 1)\n",
    "to = len(true_gamma_1)+1\n",
    "leg1 = [r\"$\\hat \\gamma^1_{%s}$\" % j for j in range(1, to)]\n",
    "leg2 = [r\"$\\gamma^1_{%s}$\" % j for j in range(1, to)]\n",
    "visualize_vect_learning(learner, \"gamma_1\", r\"$\\gamma_1$\", true_gamma_1, leg1, leg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gamma_0_true = true_gamma_0\n",
    "gamma_0_est = learner.theta[\"gamma_0\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fontsize = 16\n",
    "ax = fig.add_subplot(121)\n",
    "ax.stem(np.arange(len(gamma_0_true)).tolist(), gamma_0_true, linefmt='g-', markerfmt='go', label= r\"$\\gamma_0$\")\n",
    "ax.stem((np.arange(len(gamma_0_est)) + .5).tolist(), gamma_0_est, linefmt='r-', markerfmt='rx', label= r\"$\\hat \\gamma_0$\")\n",
    "ax.set_xlim([-5, len(true_gamma_0) + 5])\n",
    "ax.set_title(r\"$\\gamma_0$ and its estimation\", fontsize=fontsize+4)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "visualize_vect_per_group(gamma_0_true, n_long_features, ax)\n",
    "\n",
    "gamma_1_true = true_gamma_1\n",
    "gamma_1_est = learner.theta[\"gamma_1\"]\n",
    "ax = fig.add_subplot(122)\n",
    "ax.stem(np.arange(len(gamma_1_true)).tolist(), gamma_1_true, linefmt='g-', markerfmt='go', label= r\"$\\gamma_1$\")\n",
    "ax.stem((np.arange(len(gamma_1_est)) + .5).tolist(), gamma_1_est, linefmt='r-', markerfmt='rx', label= r\"$\\hat \\gamma_1$\")\n",
    "ax.set_xlim([-5, len(true_gamma_1) + 5])\n",
    "ax.set_title(r\"$\\gamma_1$ and its estimation\", fontsize=fontsize+4)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "visualize_vect_per_group(gamma_1_true, n_long_features, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "fig.suptitle('Variance-covariance matrix and its estimation')\n",
    "\n",
    "sns.heatmap(\n",
    "    data=simu.long_cov, \n",
    "    vmin=-.01, vmax=.01, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True, ax=axes[0]\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    data=learner.theta[\"long_cov\"], \n",
    "    vmin=-.01, vmax=.01, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True, ax=axes[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_cov_history = learner.history.values[\"long_cov\"]\n",
    "fig, axes = plt.subplots(len(long_cov_history), 1, figsize=(5, 5 * len(long_cov_history)), sharey=True)\n",
    "for i in range(len(long_cov_history)):\n",
    "    sns.heatmap(\n",
    "    data=long_cov_history[i], \n",
    "    vmin=-.01, vmax=.01, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True, ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(\"Iteration {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = learner.theta[\"baseline_hazard\"].index.values\n",
    "est_value = learner.theta[\"baseline_hazard\"].values\n",
    "true_value = (simu.scale * simu.shape) * np.exp(simu.shape * times)\n",
    "non_zero_idx = np.argwhere(est_value != 0)\n",
    "ratio = np.mean(true_value[non_zero_idx] / est_value[non_zero_idx])\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.bar(times, np.log10(1 + true_value), color = 'b', width = 0.5)\n",
    "plt.bar(times + 0.25, np.log10(1 + est_value * ratio), color = 'r', width = 0.25)\n",
    "plt.yscale('log')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalutation here\n",
    "marker_train = learner.predict_marker(X_train, Y_train)\n",
    "c_index_train = c_index_score(T_train, marker_train, delta_train)\n",
    "c_index_train = max(c_index_train, 1 - c_index_train)\n",
    "\n",
    "## Obtain the marker vector on test set ##\n",
    "\n",
    "# prediction here\n",
    "marker_test = learner.predict_marker(X_test, Y_test)\n",
    "c_index_test = c_index_score(T_test, marker_test, delta_test)\n",
    "c_index_test = max(c_index_test, 1 - c_index_test)\n",
    "\n",
    "print(\"Done predicting on dataset.\")\n",
    "print(\"C-index on train: %.2f\" % c_index_train)\n",
    "print(\"C-index on test: %.2f\" % c_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.stem(np.arange(len(marker_train)).tolist(), marker_train)\n",
    "ax.set_xlim([-5, len(marker_train) + 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".env385",
   "language": "python",
   "name": ".env385"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
